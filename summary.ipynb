{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forcing mechanisms for drifters entering and exiting Galveston Bay\n",
    "\n",
    "An on-going area of interest for response efforts at the Texas General Land Office is under what conditions oil may exit or enter a given bay. Here, we limit our scope to Galveston Bay and use statistics to find relationships between drifter entrances/exits and potential forcing mechanisms.\n",
    "\n",
    "## Relevant previous effort\n",
    "\n",
    "This work builds on already-existing shelf model output (DJ's [20 year hindcast](http://barataria.tamu.edu:8080/thredds/dodsC/NcML/txla_hindcast_agg)) and Dongyu's effort to blended the \"coarse\" resolution Galveston Bay model with the shelf model to create a blended model product for seamlessly running drifters. The drifter simulations here are run using the blended model product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the drifters\n",
    "\n",
    "The drifters were run on hafen (`/raid/home/kthyng/projects/bay/`) using the run.py script. Pertinent simulation details:\n",
    "\n",
    "* Output drifter locations every 15 minutes\n",
    "* Ran forward/backward for 14 days\n",
    "* Circulation model output is hourly\n",
    "* Surface drifters\n",
    "* No subgrid diffusion\n",
    "* 300 meter initial distance between drifters\n",
    "* Drifters started in uniform array within bay\n",
    "* Simulations are started from 4 dates:\n",
    " * 2010-02-01: winter winds, high river discharge\n",
    " * 2011-02-01: winter winds, low river discharge\n",
    " * 2010-07-01: summer winds, high river discharge\n",
    " * 2011-07-01: summer winds, low river discharge\n",
    "* Simulations are run forward from the dates listed above, and backward from 2 weeks after the dates listed above. That is, the forward- and backward-running simulations are simulataneous but represent drifters exiting and entering the domain (respectively).\n",
    "* New simulations are started every 4 hours for 2 weeks for a total number of simulations of: 6 * 14=84 simulations for each set (i.e. season and run direction)\n",
    "* Each simulation has 13,340 drifters, so each set (i.e. season and run direction) has 13340 * 84=1,120,560 drifters or over 1.1 million.\n",
    "\n",
    "Note that the appropriate file names for these simulations fit the pattern: `2010-02-01_forward_14days_dx300` (or backward).\n",
    "\n",
    "The simulations have already been run using:\n",
    "\n",
    "    python2 run.py > logs/[etc] &\n",
    "\n",
    "The drifter tracks are stored on hafen in `tracks`.\n",
    "\n",
    "The figure below shows the initial drifter locations.\n",
    "![](figures/starting_points_bay_dx300.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When are drifters moving between the bay and the shelf?\n",
    "\n",
    "### Run the analysis\n",
    "This analysis was run with calcs.io() with changing refdates through the simulation start dates (2010-02-01, 2011-02-01, 2010-07-01, 2011-07-01) and also the backward-running simulations (2010-02-15, 2011-02-15, 2010-07-15, 2011-07-15). This gives files of the pattern `calcs/enterexit_sim3_[yyyy]-[mm]-forward_14days_dx300` (or backward).\n",
    "\n",
    "### Calculate dataframes\n",
    "Summarize into a `pandas` dataframe the forcing mechanisms (read in from the blended model product, the shelf model, etc) for each time period and combine it with the time series summary of when drifters are outside the domain. Do this using `calcs.make_dfs()`, and the files are in the form `df_2010-02_backward.csv`.\n",
    "\n",
    "This was all done on hafen, but the df files have been copied to Tahoma too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find relationships between drifter behavior and forcing mechanisms for each set of simulations individually\n",
    "\n",
    "Run statistics in calcs.stats().\n",
    "\n",
    "subtidal vs. tidal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation set: calcs/df_2010-02_forward.csv\n",
      "Number of combinations checked: 59\n",
      "Top adjusted r^2, lowest BIC performers, no p>0.1: 4\n",
      "Adjusted r^2: 0.86\n",
      "BIC: 2272\n",
      "coefficients: \n",
      "Intercept   -30.340305\n",
      "river         0.753698\n",
      "uwind         0.183440\n",
      "theta       -15.875531\n",
      "pvalues: \n",
      "river     0.000000e+00\n",
      "uwind    1.621830e-126\n",
      "theta     0.000000e+00\n",
      "\n",
      "Adjusted r^2: 0.84\n",
      "BIC: 2606\n",
      "coefficients: \n",
      "Intercept   -34.210658\n",
      "river         0.784992\n",
      "s            -0.135435\n",
      "theta       -17.957780\n",
      "pvalues: \n",
      "river    0.000000e+00\n",
      "s        5.900459e-54\n",
      "theta    0.000000e+00\n",
      "\n",
      "Adjusted r^2: 0.85\n",
      "BIC: 2374\n",
      "coefficients: \n",
      "Intercept   -30.415900\n",
      "river         0.768867\n",
      "theta       -15.886888\n",
      "sustr         0.140292\n",
      "pvalues: \n",
      "river     0.000000e+00\n",
      "theta     0.000000e+00\n",
      "sustr    2.620875e-104\n",
      "\n",
      "Adjusted r^2: 0.82\n",
      "BIC: 2838\n",
      "coefficients: \n",
      "Intercept   -33.423779\n",
      "river         0.800416\n",
      "theta       -17.476123\n",
      "pvalues: \n",
      "river    0.0\n",
      "theta    0.0\n",
      "\n",
      "Simulation set: calcs/df_2010-07_forward.csv\n",
      "Number of combinations checked: 59\n",
      "Top adjusted r^2, lowest BIC performers, no p>0.1: 5\n",
      "Adjusted r^2: 0.23\n",
      "BIC: 6465\n",
      "coefficients: \n",
      "Intercept    32.195686\n",
      "river         0.100963\n",
      "uwind        -0.220065\n",
      "theta        18.317189\n",
      "pvalues: \n",
      "river    3.253447e-05\n",
      "uwind    1.506895e-23\n",
      "theta    7.011408e-65\n",
      "\n",
      "Adjusted r^2: 0.25\n",
      "BIC: 6395\n",
      "coefficients: \n",
      "Intercept    27.994977\n",
      "river         0.310725\n",
      "theta        15.873382\n",
      "svstr        -0.590549\n",
      "pvalues: \n",
      "river    1.059699e-39\n",
      "theta    2.244244e-54\n",
      "svstr    5.807559e-39\n",
      "\n",
      "Adjusted r^2: 0.23\n",
      "BIC: 6471\n",
      "coefficients: \n",
      "Intercept    26.916504\n",
      "river         0.288289\n",
      "vwind        -0.404386\n",
      "theta        15.275915\n",
      "pvalues: \n",
      "river    3.418263e-33\n",
      "vwind    2.768740e-22\n",
      "theta    3.324045e-49\n",
      "\n",
      "Adjusted r^2: 0.27\n",
      "BIC: 6326\n",
      "coefficients: \n",
      "Intercept    30.332551\n",
      "river         0.293329\n",
      "s            -0.347160\n",
      "theta        17.377294\n",
      "pvalues: \n",
      "river    9.343116e-39\n",
      "s        5.602123e-54\n",
      "theta    3.759421e-65\n",
      "\n",
      "Adjusted r^2: 0.22\n",
      "BIC: 6475\n",
      "coefficients: \n",
      "Intercept    36.520024\n",
      "uwind        -0.258102\n",
      "theta        20.751301\n",
      "pvalues: \n",
      "uwind     1.701780e-37\n",
      "theta    1.685014e-113\n",
      "\n",
      "Simulation set: calcs/df_2011-02_forward.csv\n",
      "Number of combinations checked: 59\n",
      "Top adjusted r^2, lowest BIC performers, no p>0.1: 5\n",
      "Adjusted r^2: 0.52\n",
      "BIC: 5263\n",
      "coefficients: \n",
      "Intercept   -92.352282\n",
      "river         2.120243\n",
      "uwind         0.250280\n",
      "theta       -52.616699\n",
      "pvalues: \n",
      "river    2.373250e-14\n",
      "uwind    1.048265e-57\n",
      "theta    0.000000e+00\n",
      "\n",
      "Adjusted r^2: 0.53\n",
      "BIC: 5253\n",
      "coefficients: \n",
      "Intercept   -91.572474\n",
      "river         2.753051\n",
      "theta       -52.358221\n",
      "sustr         0.287972\n",
      "pvalues: \n",
      "river    4.052987e-21\n",
      "theta    0.000000e+00\n",
      "sustr    7.194134e-60\n",
      "\n",
      "Adjusted r^2: 0.55\n",
      "BIC: 5099\n",
      "coefficients: \n",
      "Intercept   -69.563001\n",
      "river         4.483883\n",
      "vwind         0.343360\n",
      "theta       -40.458892\n",
      "pvalues: \n",
      "river     1.230494e-45\n",
      "vwind     3.245195e-93\n",
      "theta    7.568896e-223\n",
      "\n",
      "Adjusted r^2: 0.52\n",
      "BIC: 5293\n",
      "coefficients: \n",
      "Intercept   -68.787355\n",
      "vwind         0.209715\n",
      "theta       -38.776476\n",
      "pvalues: \n",
      "vwind     9.541097e-51\n",
      "theta    3.242688e-196\n",
      "\n",
      "Adjusted r^2: 0.51\n",
      "BIC: 5313\n",
      "coefficients: \n",
      "Intercept   -86.625298\n",
      "uwind         0.213122\n",
      "theta       -48.805101\n",
      "pvalues: \n",
      "uwind    2.417985e-46\n",
      "theta    0.000000e+00\n",
      "\n",
      "Simulation set: calcs/df_2011-07_forward.csv\n",
      "Number of combinations checked: 59\n",
      "Top adjusted r^2, lowest BIC performers, no p>0.1: 5\n",
      "Adjusted r^2: 0.18\n",
      "BIC: 6622\n",
      "coefficients: \n",
      "Intercept    22.310277\n",
      "river        -2.323311\n",
      "s             0.200410\n",
      "theta        12.887031\n",
      "pvalues: \n",
      "river    3.475818e-14\n",
      "s        3.936411e-09\n",
      "theta    5.750184e-55\n",
      "\n",
      "Adjusted r^2: 0.22\n",
      "BIC: 6481\n",
      "coefficients: \n",
      "Intercept    24.581911\n",
      "river        -1.979569\n",
      "uwind         0.476757\n",
      "theta        14.299375\n",
      "pvalues: \n",
      "river    3.178071e-11\n",
      "uwind    4.902459e-40\n",
      "theta    4.531291e-70\n",
      "\n",
      "Adjusted r^2: 0.22\n",
      "BIC: 6501\n",
      "coefficients: \n",
      "Intercept    24.289238\n",
      "river        -1.895910\n",
      "theta        14.102132\n",
      "sustr         0.625668\n",
      "pvalues: \n",
      "river    2.902373e-10\n",
      "theta    5.767867e-68\n",
      "sustr    1.142934e-35\n",
      "\n",
      "Adjusted r^2: 0.21\n",
      "BIC: 6533\n",
      "coefficients: \n",
      "Intercept    29.495022\n",
      "theta        16.433509\n",
      "sustr         0.680118\n",
      "pvalues: \n",
      "theta    1.084525e-110\n",
      "sustr     3.331671e-42\n",
      "\n",
      "Adjusted r^2: 0.21\n",
      "BIC: 6518\n",
      "coefficients: \n",
      "Intercept    30.003355\n",
      "uwind         0.510743\n",
      "theta        16.723076\n",
      "pvalues: \n",
      "uwind     1.262786e-45\n",
      "theta    5.621448e-114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import calcs\n",
    "calcs.stats(which='subtidal', direction='forward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes to add somewhere\n",
    "\n",
    "Bayesian information Criterion [(BIC)](https://en.wikipedia.org/wiki/Bayesian_information_criterion)\n",
    "\n",
    "| ΔBIC   |\tEvidence against higher BIC       |\n",
    "|--------|-------------------------------------|\n",
    "| 0 to 2 |\tNot worth more than a bare mention |\n",
    "| 2 to 6 | Positive |\n",
    "| 6 to 10 |\tStrong |\n",
    "| >10 |\tVery Strong |\n",
    "\n",
    "\n",
    "[Scaling variables:](http://stats.stackexchange.com/questions/29781/when-conducting-multiple-regression-when-should-you-center-your-predictor-varia)\n",
    "\n",
    ">In regression, it is often recommended to center the variables so that the predictors have mean 00. This makes it so the intercept term is interpreted as the expected value of YiYi when the predictor values are set to their means. Otherwise, the intercept is interpreted as the expected value of YiYi when the predictors are set to 0, which may not be a realistic or interpretable situation (e.g. what if the predictors were height and weight?). Another practical reason for scaling in regression is when one variable has a very large scale, e.g. if you were using population size of a country as a predictor. In that case, the regression coefficients may be on a very small order of magnitude (e.g. 10−610−6) which can be a little annoying when you're reading computer output, so you may convert the variable to, for example, population size in millions. The convention that you standardize predictions primarily exists so that the units of the regression coefficients are the same.\n",
    "\n",
    ">As @gung alludes to and @MånsT shows explicitly (+1 to both, btw), centering/scaling does not effect your statistical inference in regression models - the estimates are adjusted appropriately and the pp-values will be the same.\n",
    "\n",
    ">Other situations where centering and/or scaling may be useful:\n",
    "\n",
    ">* when you're trying to sum or average variables that are on different scales, perhaps to create a composite score of some kind. Without scaling, it may be the case that one variable has a larger impact on the sum due purely to its scale, which may be undesirable.\n",
    ">* To simplify calculations and notation. For example, the sample covariance matrix of a matrix of values centered by their sample means is simply X′XX′X. Similarly, if a univariate random variable XX has been mean centered, then var(X)=E(X2)var(X)=E(X2) and the variance can be estimated from a sample by looking at the sample mean of the squares of the observed values.\n",
    ">* Related to aforementioned, PCA can only be interpreted as the singular value decomposition of a data matrix when the columns have first been centered by their means.\n",
    "\n",
    ">Note that scaling is not necessary in the last two bullet points I mentioned and centering may not be necessary in the first bullet I mentioned, so the two do not need to go hand and hand at all times.\n",
    "\n",
    "\n",
    "[Standardize variables](http://stats.stackexchange.com/questions/13267/how-to-sum-two-variables-that-are-on-different-scales/13271#13271) by:\n",
    "\n",
    "$C_{scaled} = (C - C_{mean})/ C_{std}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0rc4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
